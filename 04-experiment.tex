In this section, we present a specific example of the method described in Section~\ref{sec:methodology}, namely of the FLOSS domain.

\subsection{Defining the dimensions for evaluating team members}

Universal psycho-social components were already identified in 
Section~\ref{sec:related}. Our objective was therefore to identify
technical skills specific to the domain.

The literature on skills required for FLOSS development is sparse.

\citet{david:2007:free} considered which skills software developers improve through participation in FLOSS. The study was conducted as a survey of FLOSS developers, human resource managers, and universities, in eight countries. Participants were asked to identify, from a list of 30 skills, those which developers most successfully acquired
through FLOSS participation. The skills are grouped as general, legal, managerial, and technical, but the source of the skills is not specified.
The technical category contains:
  to re-use code written by others,
  to run and maintain complex software systems,
  basic/introductory programming skills,
  to look for and fix bugs,
  to become familiar with different programming languages,
  to write code in a way that can be re-used,
  to design modular code,
  to document code, and
  to create new algorithms.

\cite{Kimmelmann13} used grounded theory on guided interviews with 
developers who participate in FLOSS development as a component of their
employment. Their team managers and human resource managers were also
interviewed. She identified three types of skills---technical,
social and personal---which were grouped according to how they
pertained to distinctive elements of FLOSS development. The technical
skills listed are:
programming, ``architectural competency,'' ``implementation of new features without disturbing others,'' quick induction into new projects, implementation of feedback, dealing with technical problems, identification of possible successful projects, gaining recognition and earning reputation, high number of quality patches, and documentation of work. 
These concepts have different levels of granularity. For instance
the concept of programming might be considered to contain the aspect
of quality patches, while the concepts of quality and quantity of patches are combined in one skill.

\cite{barcomb:2015:developers} conducted a survey to determine if
FLOSS developers had a greater preference for informal learning
styles than other software developers. They created a list of 17
highly trainable skills based on \cite{Kimmelmann13} and
\cite{david:2007:free}, which contained the following technical skills:
to evaluate the work of others;
to work on own software module alone;
to communicate with many different target groups;
to understand English, especially technical discussion;
to document code;
to clearly articulate an argument;
to understand different software architectures;
to follow discussions on mailing lists;
%% to communicate without offending others;
to write code in a way that can be reused;
basic/introductory programing skills;
to acquaint yourself with code from others;
to maintain contact with a community;
to coordinate own work with the work of others; and
%% to change criticized behavior
to understand and work with people from different cultures.

None of the lists of FLOSS skills we identified in the literature was suitable for our purpose for two reasons. First, they
are not at the same level of granularity as the psychological factors, which we
incorporated because they are universal and well-established by research, and therefore 
can be applied to any teaming situation. Second, the lists are too lengthy to allow participants to keep all attributes in mind. Considering other domains risked diluting the specific situation
we wished to observe. Therefore, we synthesized the aforementioned literature to nine
dimensions summarizing the technical skills:
% In their work describing the management of outsourced global software development in India, \citet{deshpande:2009:management} include a list of criteria which includes the skills domain knowledge, cultural background, knowledge of English, professional skills, technical experience, and other language skills, and the additional factors technical requirements and gender. These categories were derived from interviews and are clearly specific to the context.
{\em produces code of quality};
{\em understands the architecture of the code (modular code, code dependencies)};
{\em proposes implementation of new features without disturbing others};
{\em contributes a lot of commits};
{\em documents the work produced};
{\em writes clearly, in good English};
{\em implements the feedback received};
{\em is good at describing bugs}; and
{\em is good at specifying features}.
Because the next stage of the process involved validating the criteria through
interviews with DMs, the risk of overlooking a critical factor was extremely low.
At this stage there were five psychological and nine technical candidate criteria.

Next, we interviewed experts, in this case six DMs, using a semi-structured
interview and a questionnaire containing the criteria we previously 
identified. The questionnaire consisted of the information presented in
Table~\ref{tab:description-dimensions} and the question
``To which extent are these dimensions useful and important for you 
to assess the quality of a member of your community?'' for which the options were
`Very important,' `Important,' `Neutral,' `Not very important,' and
`Not important at all.' The interview script can be found in the Appendix.
%% ref{app:interview}

According to these DMs, psychological qualities were at least as important as technical capabilities. Also, the dimensions we presented were consistent and complete enough to allow for the evaluation of team members. As an additional confirmation, we reviewed the free-form answers in the interviews and compared the concepts to our list, and subsequently revised the categories to use the language of our participants. 
For example, ``commitment'' became ``commitment to the project'' based on interview data such as:
\begin{quote}
{\em
I think the level of interest in somebody is one of the biggest predictors---I 
mean if they're excited about what's going on, if they're excited about the 
mission and excited about the community that to me---that comes well before level of knowledge in the project itself or technical skill, or other things. I think that comes. If somebody's not motivated, and excited, I think the other things don't matter as much. So I would say at a simple level, just level of interest 
and excitement.} (\DB)
\end{quote}

After interviewing all six DMs, we found that no new attributes were
mentioned, suggesting that our list was sufficiently comprehensive. 
Four of the technical criteria were considered unimportant by all 
participants. We therefore decided to drop these dimensions because
they did not assist our DMs in assessing team members.
The final dimensions, five psycho-social and five technical, are presented as an illustration of the method in Table~\ref{tab:description-dimensions}. These dimensions are the same for every DM.

\input{tab-dimension-descriptions}

\subsection{Selecting the criteria for the MCDA analysis}\label{sec:results:sub:subset}

While all DMs agreed that the ten dimensions captured all attributes they would use to evaluate team members, they did not agree on the number of or the selection of criteria, as seen by their responses to the questionnaire where they
rated the relevance of the dimensions on a 5-item scale.
The exact choices of the DMs is discussed in more detail in Section~\ref{sec:discussion} and described in Table~\ref{tab:criteria}. This result advocates for a manager-based methodology, where each DM is able to identify a tailored subset of key factors from a longer list of attributes relevant to the domain.

We proceeded with each DM using the criteria they considered important or
very important. As each DM selected at least half of the criteria as
relevant, it would not have been possible for the unselected factors to
collectively deliver more relevance than the chosen factors. Limiting the
factors also improved the DM's ability to effectively consider example
team members.

\subsection{Inferring the manger's preferences}\label{sec:results:sub:model}

Although six DMs participated in our research, we have chosen to provide
a detailed account of two participants. Our reasoning was based on the goal of the paper, which is to present the methodology and demonstrate how it can provide new results for the DM and for researchers on the interaction between a DM and virtual team members. We considered it more important to describe in detail a minimal set of examples, rather than to discuss all cases superficially or to significantly lengthen the paper without providing new information about the process, potentially creating the false impression that we are conducting a qualitative study of FLOSS DMs. The extension of the number of DM beyond the two we present and the six total interviews toward more general studies is of course the next step, which will be described further in Section~\ref{sec:discussion}.

 We chose to report on \GJ and \DB for two reasons.
First, these DMs selected the same criteria in the previous phase,
which allows us to illustrate how the method performs when the DMs
are concerned with the same dimensions. Differences between the two
inferred preference models demonstrates the difficulty of creating a
general evaluation, and the benefit in a customized approach. Second,
\GJ and \DB both selected fewer dimensions than other participants.
With fewer dimensions, the models are simpler and the differences between
the models are more readily evident.
The five dimensions chosen by \GJ and \DB were:
\begin{itemize}
\item Commitment to the project ($c_1$), psycho-sociological;
\item Ability to work with others ($c_2$), psycho-sociological;
\item Quality of produced code ($c_3$), technical;
\item Understanding of the tools, technologies, domain and process behind the project ($c_4$), technical;
\item Documentation skills ($c_5$), technical.
\end{itemize}

Mock profiles---alternatives in an MCDA context---were created using the aforementioned five dimensions, with each trait described using a five-level ordinal scale ranging from very bad to very good ($\{vb, b, n, g, vg\}$). The DMs rated these profiles as good, neutral and bad (hence \\$K = \{Bad, Neutral, Good\}$).

\subsubsection{Inferring the preference model of \GJ}

We started the first iteration by generating an initial set of 25 team member profiles, which \GJ assigned to one of the categories in $K$, while explaining his reasoning to one of the paper's authors. \GJ's assignments are illustrated in Table~\ref{tab:ex1-data1}.

\input{input/ex1-data1.tex}

We then tried to fit these assignment examples with an MR-Sort model with a simple majority rule, but only 23 of the 25 responses could be fit. We therefore proceeded to generate a series of sets of the two profiles along with their alternative class assignments which would allow this model to fit. These sets are illustrated in Table~\ref{tab:ex1-altassig1}.

\input{input/ex1-altassig1.tex}

Using these sets, we devised a series of questions for the DM to simplify his task of considering these alternative assignments. As the second team member profile appeared in all three sets, we asked if he would agree to change his assignment from Neutral to Bad. \GJ agreed to change his assignment, and confirmed that he had initially hesitated between these two categories. We continued by asking him if he would agree to changing the assignments of any of the other profiles from the three sets, but he disagreed. Consequently we increased the complexity of the model and found that an MR-Sort model with vetoes was able to capture all 25 profile assignments.

This ended the step of fitting a model for the first iteration, leading to the model illustrated in Figure~\ref{fig:ex1-model1}. The first diagram shows the limit between the Bad and Neutral classes, while the second shows the boundary between Neutral and Good. The lines correspond to the limits, while the dark regions represent the range of values which would trigger a veto. At this point, the model is not yet presented to the DM so no attempt is made to derive examples from it.

\input{input/ex1-model1.tex}

We were therefore able to complete the first iteration of our protocol and proceeded to check if a stopping condition was met. The assignment examples did not restrict the model very much, and, as \GJ was willing to continue, we began a second iteration.

An additional set of 10 profiles were generated, based on the previously created model. This set was presented to \GJ who assigned them as seen in Table~\ref{tab:ex1-data2}. This was again done interactively with a researcher present.

\input{input/ex1-data2.tex}

We combined the initial set of 25 profiles with the new set of 10 and tested whether an MR-Sort model with vetoes was still able to capture them. This model did not completely fit the assignments. We therefore proceeded to check if \GJ had any hesitations in his assignments which would allow this model to be used. Five sets of alternative class assignments, shown in Table~\ref{tab:ex1-altassig2}, were generated to explore this possibility.

\input{input/ex1-altassig2.tex}

We observed that the first four sets contained the second team member profile, which \GJ had already agreed to change. Therefore, we continued by first asking if he would also agree to an alternative assignment for one of the remaining profiles in these sets. \GJ did not accept changing the assignment profiles 16, 33 or 34, especially for the third set where the alternative assignment strongly contradicted the initial assignment. However, \GJ agreed to change the assignment of profile 35, so we continued to use an MR-Sort model with vetoes, as depicted in Figure~\ref{fig:ex1-model2}.

\input{input/ex1-model2.tex}

With the second iteration of preference modeling completed, we checked to determine if the process was complete. Given the existing model, a bare 8 profiles would suffice to express the limits. \GJ agreed to another iteration.

We generated the $8$ new profiles, and asked \GJ to assign them during an interview. The results of this assignment are presented in Table~\ref{tab:ex1-data3}.

\input{input/ex1-data3.tex}

After adding the new profiles and their assignments to the existing ones, we found that an MR-Sort model with vetoes was not able to represent all of the assignments. We generated three possible profile changes, as shown in Table~\ref{tab:ex1-altassig3}.

\input{input/ex1-altassig3.tex}

Profiles 33 and 34 reoccurred, but we were already aware that \GJ did not want to change these profiles. Therefore we only inquired on the possibility of changing profile 14. \GJ felt strongly about retaining his initial assessment, motivating us to test a more complex model. We applied an MR-Sort model with vetoes weakened by dictators, as it was closest to our previous model. This model, illustrated in Figure~\ref{fig:ex1-model3}, was able to reflect all of \GJ's assignments from the first three iterations.

\input{input/ex1-model3.tex}

We checked if the stopping condition was met. There were 14 profiles which might be generated around category limits, but \GJ wished to review the model we had generated. In order to allow \GJ to validate the model, we presented a series of rules derived from it, depicted in Figure~\ref{fig:ex1-rules-reduced}. The rules were displayed as a series of graphs showing all combinations of evaluations that a good or bad team member could have. The rules for the neutral category were not included, as they can be inferred as a compliment of the rules for the good and bad team members. In order to minimize the number of rules per category, we allowed for some overlap to occur.

\input{input/ex1-rules-reduced.tex}

We explained the interpretation of the rules verbally to 
\GJ, who validated the illustrated rules without making any changes to them.

\subsubsection{Inferring the preference model of \DB}

We started with the same set of 25 alternatives initially used by \GJ to better illustrate the differences between the two DMs. \DB's assignments are shown in Table~\ref{tab:ex2-data1}. During this process one author was also on hand to record any rationale expressed by \DB.

\input{input/ex2-data1.tex}

We tried to fit the data with an MR-Sort model and found that at most 24 of the 25 assignment examples could be captured with this type of model. Therefore we provided the DM with the possible sets of alternatives shown in Table~\ref{tab:ex2-altassig1}.

\input{input/ex2-altassig1.tex}

\DB had already verbally expressed hesitation in assigning the eigth profile, and therefore agreed to change his assignment. The resulting MR-Sort model is presented in Figure~\ref{fig:ex2-model1}.

\input{input/ex2-model1.tex}

We continued with a second iteration by generating an additional 10 profiles based on the existing model. This new set was presented to \DB, who assigned them as shown in Table~\ref{tab:ex2-data2}.

\input{input/ex2-data2.tex}

We combined the initial 25 profiles with the 10 new profiles and checked their fit with an MR-Sort model. As only 33 out of the 35 profiles could be represented by this model, we proceeded to determine if the DM would accept adapting a minimal number of his assignments. Only one set of profile changes would make this possible. This option is shown in Table~\ref{tab:ex2-altassig2}.

\input{input/ex2-altassig2.tex}

\DB expressed a willingness to change the assignment of the first profile from this set. However, the change in assignment for the second profile was too drastic. Therefore we looked at a more complicated model, in particular an MR-Sort with vetoes or an MR-Sort with dictators, could describe the assignments. Both of these models were also unable fit the data completely, but the model with dictators required two profiles to be changed, whereas the model with vetoes only needed one profile change. Therefore we focused on the MR-Sort with vetoes. The possible profile changes are found in Table~\ref{tab:ex2-altassig3}.

\input{input/ex2-altassig3.tex}


As the DM had previously expressed a hesitation on the assignment of profile 16, he quickly agreed to the proposed changed. The model that reflects all assignments at the end of the second iteration is depicted in Figure~\ref{fig:ex2-model2}.

\input{input/ex2-model2.tex}

The model appeared to further illustrate the existence of vetoes on the first two criteria, which we had already posited from the reasoning the DM expressed in the assignment interview. \DB agreed to continue with another iteration of the protocol.

We generated an additional set of 10 profiles, which were assigned as illustrated in Table~\ref{tab:ex2-data3}.

\input{input/ex2-data3.tex}

After adding the 10 new profiles and their assignments to the existing ones, we found that an MR-Sort model with vetoes was not able to represent all of these assignments and that at least three profile assignments needed to be altered to allow for this type of model to be used. These sets are presented in Table~\ref{tab:ex2-altassig4}.

\input{input/ex2-altassig4.tex}

As profile 39 appeared in all three sets, we began with asking \DB if he hesitated in assigning this profile. As the answer was negative, we considered a more complex model. An MR-Sort model with veto weakened by a dictator was able to fully reflect all of the DM's assignments. Figure~\ref{fig:ex2-model3} presents this model.

\input{input/ex2-model3.tex}

At this point, we might have constructed a total of 27 new profiles in order to refine the model parameters. The DM, however, expressed an interest in seeing the model, which, after three iterations, already reflected a large portion of his perspective. A set of rules were generated from the model, as shown in Figure~\ref{fig:ex2-rules-reduced1}, and we explained the implications in an interview with \DB.

\input{input/ex2-rules-reduced1.tex}

\DB felt that the model was slightly inaccurate, and decided to tweak the first two rules of the Good category by raising the boundary of the second criterion from $very\ bad$ to $bad$, as he felt that being neutrally committed to the project and having a clear inability to work with others would not be a characteristic of a good team member, regardless of all other factors. In the Bad category, \DB also felt that a very committed team member should not be in the Bad category, regardless of other poor evaluations, but qualified this by mentioning that if the commitment were to fall to neutral, this would indeed be a Bad team member. The second and third rules in the Bad category were adjusted accordingly by lowering slightly the good evaluation on the second criterion to a neutral one. The final model is illustrated in Figure~\ref{fig:ex2-model4}, while the assignment rules derived from it are presented in Figure~\ref{fig:ex2-rules-reduced2}.

\input{input/ex2-model4.tex}

\input{input/ex2-rules-reduced2.tex}

In the next section we will discuss the findings from these experiments, and what it implies about the methodology and its relevance to IS and management practitioners and scholars.
